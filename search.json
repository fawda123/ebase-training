[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ecosystem Metabolism Workshop",
    "section": "",
    "text": "About this Workshop\nThis course will provide an overview of new techniques to estimate metabolic processes in estuaries using new software with the R open-source programming language. We will describe the theory and application of the new Estuarine BAyesian Single-station Estimation (EBASE) method that applies a Bayesian framework to a simple process-based model and dissolved oxygen observations, allowing the estimation of critical metabolic parameters as informed by a set of prior distributions. We will also explore how EBASE and additional R features can be used to evaluate metabolism results and to identify potential drivers of change. By the end of the course, you will understand how to prepare data for use with EBASE and to interpret the results to better understand processes that influence ecosystem status and condition. Basic R experience is expected.\nEBASE materials:",
    "crumbs": [
      "About this Workshop"
    ]
  },
  {
    "objectID": "index.html#agenda",
    "href": "index.html#agenda",
    "title": "Ecosystem Metabolism Workshop",
    "section": "Agenda",
    "text": "Agenda\nAll times EDT.\n\n\n\n\n\nTime\nTopic\n\n\n\n\n10:00\nIntroduction\n\n\n10:30\nData Preparation\n\n\n11:30\nBreak\n\n\n12:00\nUsing EBASE\n\n\n1:30\nInterpreting Results\n\n\n3:00\nAdjourn",
    "crumbs": [
      "About this Workshop"
    ]
  },
  {
    "objectID": "index.html#important-links",
    "href": "index.html#important-links",
    "title": "Ecosystem Metabolism Workshop",
    "section": "Important links",
    "text": "Important links\n\nWorkshop Website: link\nLive coding: link\nPosit Cloud: link",
    "crumbs": [
      "About this Workshop"
    ]
  },
  {
    "objectID": "index.html#housekeeping",
    "href": "index.html#housekeeping",
    "title": "Ecosystem Metabolism Workshop",
    "section": "Housekeeping",
    "text": "Housekeeping\nPlease read these housekeeping items on the day of the training so that everything runs smoothly.\n\nFeel free to verbally ask questions during the training by unmuting your microphone. You can also type questions in the chat. Other attendees are welcome to respond to questions in the chat.\n\nPlease use RStudio installed on your computer to follow along during the workshop. RStudio Cloud can also be used as a backup option. See the setup instructions below for more information.\nWe have a live coding link that we’ll be using as we go through the lessons. If you get lost, you can copy/paste code from this link into RStudio.\nAll training content is on this website. If you get lost you can view the agenda to see which lesson we’re covering.",
    "crumbs": [
      "About this Workshop"
    ]
  },
  {
    "objectID": "index.html#setup",
    "href": "index.html#setup",
    "title": "Ecosystem Metabolism Workshop",
    "section": "Setup",
    "text": "Setup\nPlease visit the setup page for instructions on preparing for this workshop. You will be required to install R, RStudio, JAGS, and several R packages prior to the workshop. Basic R experience is expected.",
    "crumbs": [
      "About this Workshop"
    ]
  },
  {
    "objectID": "index.html#code-of-conduct",
    "href": "index.html#code-of-conduct",
    "title": "Ecosystem Metabolism Workshop",
    "section": "Code of Conduct",
    "text": "Code of Conduct\nWe are dedicated to providing a welcoming and supportive environment for all people, regardless of background or identity. We are adopting The Carpentries Code of Conduct for this workshop.",
    "crumbs": [
      "About this Workshop"
    ]
  },
  {
    "objectID": "index.html#instructor",
    "href": "index.html#instructor",
    "title": "Ecosystem Metabolism Workshop",
    "section": "Instructor",
    "text": "Instructor\n\nMarcus Beck, Ph.D.\n\n\n\n\nMarcus Beck is the Program Scientist for the Tampa Bay Estuary Program in St. Petersburg, Florida and is developing data analysis and visualization methods for Bay health indicators. Marcus has experience researching environmental indicators and developing open science products to support environmental decision-making. He has been using the R statistical programming language for over 15 years and has taught several workshops on its application to environmental sciences. Marcus has also developed several R packages and currently maintains 7 on CRAN. He received a PhD in Conservation Biology with a minor in Statistics from the University of Minnesota in 2013, his Masters in Conservation Biology from the University of Minnesota in 2009, and his Bachelors in Zoology from the University of Florida in 2007. Links: Email, CV, GitHub, Scholar",
    "crumbs": [
      "About this Workshop"
    ]
  },
  {
    "objectID": "01_intro.html",
    "href": "01_intro.html",
    "title": "1  Inroduction",
    "section": "",
    "text": "1.1 Lesson Outline\nThis lesson will cover the very basics of ecosystem metabolism: what it is, why you should care about it, and what it can tell you. We’ll also make sure that RStudio is setup for the rest of the workshop.",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inroduction</span>"
    ]
  },
  {
    "objectID": "01_intro.html#learning-goals",
    "href": "01_intro.html#learning-goals",
    "title": "1  Inroduction",
    "section": "1.2 Learning Goals",
    "text": "1.2 Learning Goals\n\nLearn a basic definition of metabolism\nUnderstand what it tells you about your ecosystem\nUnderstand how it is measured\nSetup RStudio for the workshop using a project",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inroduction</span>"
    ]
  },
  {
    "objectID": "01_intro.html#what-is-ecosystem-metabolism",
    "href": "01_intro.html#what-is-ecosystem-metabolism",
    "title": "1  Inroduction",
    "section": "1.3 What is ecosystem metabolism?",
    "text": "1.3 What is ecosystem metabolism?\nSimply put, ecosystem metabolism is a measure of how quickly organic matter is consumed or produced in an aquatic environment. Estuaries are transition zones that receive materials from the land and export them to the ocean and atmosphere. Ecosystem metabolism is a measure of the rate at which this material is processed as a first order property that can affect a wide range of biogeochemical processes.\nMore specifically, ecosystem metabolism is the balance between production and respiration processes that create and consume organic matter. We can use these measures to characterize metabolism in aquatic environments as a rate, as compared to “surrogate” snapshot measures like nutrient or chlorophyll concentrations. It provides a more complete picture of the state of the environment.\nThe simplest expression of metabolism is below:\n\\[\nNEM = P - R\n\\]\nHere, net ecosystem metabolism (\\(NEM\\)) is the difference between gross primary production (\\(P\\)) and respiration (\\(R\\)). Or, net ecosystem metabolism is the difference between processes that produce organic matter and those that consume organic matter. You may also see \\(NEM\\) written as net ecosystem production (\\(NEP\\)).\n\\(NEM\\) can tell us a lot about an ecosystem:\n\nIf positive, the ecosystem is autotrophic, meaning it produces more organic matter than it consumes. Organic matter will accumulate.\nIf negative, the ecosystem is heterotrophic, meaning it consumes more organic matter than it produces. Organic matter will deplete.\n\nAutotrophy and heterotrophy can be governed by many factors. For example, autotrophy may occur more often during warmer months, as temperature can stimulate growth of algae and other primary primary producers. Similarly, hyper-eutrophic systems may be more heterotrophic during the summer as the rapid decomposition of organic matter that was produced by excess nutrients may be increased with temperature. A single pulse of nutrients can create autotrophic conditions as production increases followed by heterotrophic conditions as the new organic material settles to the bottom and is decomposed.\nThis graphic from a synthesis study of 350 sites by Hoellein et al. (2013) shows how metabolic ranges vary across different aquatic ecosystems. Here we can see that the largest ranges in production and respiration occur in estuaries and most aquatic systems tend towards heterotrophy. Note the units as grams of oxygen per m\\(^{-2}\\) per day.\n\n\n\n\n\nMost of the estuarine sites used in Hoellein et al. (2013) were from a single study by Caffrey (2004) that evaluated metabolism across all sites in the National Estuarine Research Reserve (NERR). This study was one of the first to develop a system-wide comparison of metabolic rates and several useful conclusions were made.\nFor example, metabolic rates between estuarine habitats are shown below, where most sites tend towards heterotrophy, although sites dominated by submerged aquatic vegetation are more balanced or even autotrophic.\n\n\n\n\n\nNutrients as drivers of metabolism were also evaluated by Caffrey (2004). Although the relationships were weak, sites with higher nutrient loadings tended towards autotrophy as production was generally higher than respiration.\n\n\n\n\n\nMetabolism is also temporally variable. In addition to seasonal variation, metabolism can be event-driven and respond to external and internal drivers that influence the system. A severe red tide bloom in Tampa Bay occurred in July 2021. The dissolved oxygen time series shows a clear increase and decrease as the bloom developed and then dissipated.\n\n\n\n\n\nThe change in ecosystem metabolism from autototrophy to heterotrophy tells a story about the bloom. We see an increase in production followed by an increase in respiration with bloom development and senescence. Also note the “anomalous” values for production and respiration that are negative and positive, respectively.\n\n\n\n\n\nThese quick examples demonstrate that unique information about system dynamics can be inferred from ecosystem metabolism and its components. As you learn to assess metabolism with the tools from this workshop, you can develop similar hypotheses on factors that control metabolism both within and between systems.",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inroduction</span>"
    ]
  },
  {
    "objectID": "01_intro.html#how-is-metabolism-measured",
    "href": "01_intro.html#how-is-metabolism-measured",
    "title": "1  Inroduction",
    "section": "1.4 How is metabolism measured?",
    "text": "1.4 How is metabolism measured?\nMetabolism can be measured several ways, each of which has its own strengths, weaknesses, and assumptions (Kemp and Testa 2011). These include:\n\nBottle-based incubations\nOpen-water techniques\nEcosystem budgets\nUse of oxygen isotopes or inert gases\nAquatic eddy covariance\n\nOpen-water techniques are among the more commonly used approaches applied to continuous monitoring data. These techniques exploit the diel cycle of dissolved oxygen (DO) concentration to infer metabolism. The main assumptions are:\n\nProduction produces oxygen during daylight hours\nRespiration consumes oxygen during daylight and nighttime hours\nOxygen exchanges freely with the atmosphere\nThe system is well-mixed\n\n\nThe DO time series can be deconstructed using a mass-balance equation to estimate metabolism. This is a literal deconstruction of the processes in the above figure.\n\\[\nZ\\frac{dC_d}{dt} = P - R + D\n\\]\nThe change in dissolved oxygen (\\(dC_d\\)) over time (\\(dt\\)) (a rate) is equal to the difference between production (\\(P\\)) and respiration (\\(R\\)) plus the exchange of oxygen with the atmosphere (\\(D\\)). The units are converted from volumetric (\\(m^{-3}\\)) to areal (\\(m^{-2}\\)) by multiplying the equation by water column depth (\\(Z\\)). In this example, \\(D\\) is positive for ingassing and negative for outgassing.\n\\(P\\), \\(R\\), and \\(D\\) can be estimated several ways depending on which “open-water” technique is used. The most popular method is that of Odum (1956), modified extensively by others since its original presentation. The method calculates the DO flux (DO change per unit time) during day and night periods and corrects it for gas exchange. This is also called the book-keeping method since it’s “simple” arithmetic.\nGas exchange can also be estimated several ways, but the core concept is that the flux in or out of the water is proportional to the difference between the DO saturation concentration (\\(C_s\\)) and the measured concentration in the water (\\(C_d\\)). This difference is also multiplied by a gas exchange coefficient (\\(k\\)), which can vary by wind, temperature, or other factors depending on the model.\n\\[\nD = k(C_s - C_d)\n\\]\nFortunately for us, there are existing packages in R that can estimate these parameters. One is the WtRegDO package that uses the Odum technique (Beck et al. 2015), which was covered in a workshop a few years ago. Another is EBASE, which we’ll discuss today. EBASE follows the same general principles as the Odum technique, but differs in the statistical method to estimate the parameter (i.e., Bayesian) and the model used for each parameter (Beck et al. 2024).\nWe’ll talk more about how EBASE estimates metabolism in Lesson 3, but first we need to get setup with R and prepare our data in Lesson 2.",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inroduction</span>"
    ]
  },
  {
    "objectID": "01_intro.html#get-ready-for-the-workshop",
    "href": "01_intro.html#get-ready-for-the-workshop",
    "title": "1  Inroduction",
    "section": "1.5 Get ready for the workshop",
    "text": "1.5 Get ready for the workshop\nLet’s make sure RStudio is setup for the workshop. We’ll use a project to keep everything in one place, for good reason. There are people that will set your computer on fire if you don’t follow these best practices.\nLet’s run through the basics of creating a project in RStudio.\n\nCreate a new project in RStudio, first open RStudio and select “New project” from the File menu at the top.\n\nThen select “New Directory”.\n\nThen select “New Project”. Create a directory in a location that’s easy to find.\n\nClick “Create Project” when you’re done.\nA fresh RStudio session will open. Open a new R script by selecting “New file” &gt; “R Script” from the File menu at the top.\n\nSave the file in your working directory by clicking the file icon on the top right. Give it an informative name. For example, “ebase_intro.R”. The file should be saved to the project root or home directory.\n\nSetup the package imports at the top of the script. These should already be installed during the setup prior to the workshop.\nlibrary(EBASE)\nlibrary(SWMPr)\nlibrary(tidyverse)\nlibrary(plotly)\nSave the script again and send the commands from the source script to the console. Do they load properly??\nSetup a data folder in the project directory. This is where we’ll store the data for the workshop.\nSelect “New folder” from the file pane (bottom right). \nName the folder “data” and save it in the project root directory.\nDownload the zipped data file from GitHub: https://github.com/fawda123/ebase-training/raw/main/data/367272.zip\nPlace the downloaded data in this folder. There’s no need to unzip it.",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inroduction</span>"
    ]
  },
  {
    "objectID": "01_intro.html#next-steps",
    "href": "01_intro.html#next-steps",
    "title": "1  Inroduction",
    "section": "1.6 Next steps",
    "text": "1.6 Next steps\nIn this lesson we learned the basics about metabolism and made sure RStudio is ready to go for the rest of the workshop. Next we’ll learn how to import and prepare data with SWMPr and other packages for analysis with EBASE.\n\n\n\n\nBeck, M. W., J. M. Arriola, M. Herrmann, and R. G. Najjar. 2024. Fitting metabolic models to dissolved oxygen data: The estuarine bayesian single-station estimation method. Limnology and Oceanography: Methods 22: 590–607. doi:10.1002/lom3.10620\n\n\nBeck, M. W., J. D. Hagy III, and M. C. Murrell. 2015. Improving estimates of ecosystem metabolism by reducing effects of tidal advection on dissolved oxygen time series. Limnology and Oceanography: Methods 13: 731–745. doi:10.1002/lom3.10062\n\n\nCaffrey, J. M. 2004. Factors controlling net ecosystem metabolism in U.S. estuaries. Estuaries 27: 90–101. doi:10.1007/bf02803563\n\n\nHoellein, T. J., D. A. Bruesewitz, and D. C. Richardson. 2013. Revisiting Odum (1956): A synthesis of aquatic ecosystem metabolism. Limnology and Oceanography 58: 2089–2100. doi:10.4319/lo.2013.58.6.2089\n\n\nKemp, W. M., and J. M. Testa. 2011. Metabolic balance between ecosystem production and consumption, p. 83–118. In E. Wolanski and D. McLusky [eds.], Treatise on estuarine and coastal science. Elsevier.\n\n\nOdum, H. T. 1956. Primary production in flowing waters. Limnology and Oceanography 1: 102–117.",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inroduction</span>"
    ]
  },
  {
    "objectID": "02_dataprep.html",
    "href": "02_dataprep.html",
    "title": "2  Data Preparation",
    "section": "",
    "text": "2.1 Lesson Outline\nThe EBASE software requires a specific format for input data that includes both water quality and weather data. This lesson will demonstrate how the SWMPr package can be used to import and prepare data from the NERRS System Wide Monitoring Program (SWMP) for analysis. We’ll also cover how to prepare non-SWMP data using R packages from the tidyverse.",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "02_dataprep.html#learning-goals",
    "href": "02_dataprep.html#learning-goals",
    "title": "2  Data Preparation",
    "section": "2.2 Learning Goals",
    "text": "2.2 Learning Goals\n\nUnderstand the data requirements for EBASE\nLearn how to import data with SWMPr\nLearn how to clean and combine SWMP data\nLearn how to prepare data for EBASE analysis with other tools",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "02_dataprep.html#sec-ebasedata",
    "href": "02_dataprep.html#sec-ebasedata",
    "title": "2  Data Preparation",
    "section": "2.3 Data requirements for EBASE",
    "text": "2.3 Data requirements for EBASE\nThe metabolism functions in EBASE require both water quality and weather data. Both are assumed continuous where sufficient observations are collected each day to describe the diel cycling of dissolved oxygen and other required parameters. Because water quality and weather data are collected by different sensors, these data typically are not provided in the same file. A bit of preprocessing is needed to combine the data before EBASE can be used.\nWe’ll start by loading EBASE and viewing an example file that’s included with the package. This example file is used for all the documentation in EBASE and you can use it to learn how the main functions work. We’ll use other data files below.\n\nlibrary(EBASE)\n\nView the first few rows of the example data file:\n\nhead(exdat)\n\n        DateTimeStamp DO_obs Temp  Sal PAR WSpd\n1 2012-02-23 00:00:00    8.8 16.4 23.0   0  3.6\n2 2012-02-23 00:15:00    8.8 16.4 22.8   0  3.5\n3 2012-02-23 00:30:00    8.8 16.4 22.7   0  3.6\n4 2012-02-23 00:45:00    8.8 16.4 22.9   0  4.2\n5 2012-02-23 01:00:00    8.7 16.4 22.7   0  3.6\n6 2012-02-23 01:15:00    8.5 16.4 23.4   0  4.1\n\n\nCheck the structure of the example data file:\n\nstr(exdat)\n\n'data.frame':   27648 obs. of  6 variables:\n $ DateTimeStamp: POSIXct, format: \"2012-02-23 00:00:00\" \"2012-02-23 00:15:00\" ...\n $ DO_obs       : num  8.8 8.8 8.8 8.8 8.7 8.5 8.3 8.2 7.8 8.5 ...\n $ Temp         : num  16.4 16.4 16.4 16.4 16.4 16.4 16.4 16.4 16.4 16.4 ...\n $ Sal          : num  23 22.8 22.7 22.9 22.7 23.4 24.5 24.4 24.3 23 ...\n $ PAR          : num  0 0 0 0 0 0 0 0 0 0 ...\n $ WSpd         : num  3.6 3.5 3.6 4.2 3.6 4.1 3.6 4.2 4 3.6 ...\n\n\nOnly five parameters are required to use EBASE, where each row represents a single observation indexed by ascending time.\n\nDateTimeStamp: Date and time of the observation, as a POSIXct object with an appropriate time zone.\nDO_obs: Observed dissolved oxygen concentration in mg/L.\nTemp: Water temperature in degrees Celsius.\nSal: Salinity in psu.\nPAR: Total photosynthetically active radiation in Watts per square meter.\nWSpd: Wind speed in meters per second.\n\nThe dissolved oxygen, water temperature, and salinity data are typically collected by a water quality sonde, while the PAR and wind speed data are typically collected at a weather station. We’ll discuss why these parameters are needed to calculate metabolism in Lesson 3. These data must be combined into a single data frame for EBASE to work. We’ll do this in the next few sections.",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "02_dataprep.html#data-import-with-swmpr",
    "href": "02_dataprep.html#data-import-with-swmpr",
    "title": "2  Data Preparation",
    "section": "2.4 Data import with SWMPr",
    "text": "2.4 Data import with SWMPr\nThe SWMPr package was developed in 2016 to provide a bridge between the raw data from the NERR System Wide Monitoring Program (SWMP) network and the R analysis platform (Beck 2016). It does this with some degree of proficiency, but by far it’s most useful feature is being able to import and combine time series from SWMP sites with relative ease. In particular, the import_local, qaqc, and comb functions allow us to quickly import, clean up, and combine datasets for follow-up analysis. This is all we’ll do with SWMPr in these lessons.\nThe import_local function is designed to work with SWMP data downloaded from the Centralized Data Management Office (CDMO) using the Zip Downloads feature from the Advanced Query System. The files we have in our “data” folder were requested from this feature for Apalachicola Bay data from 2017 to 2019.\nThe import_local function has two arguments: path to indicate where the data are located and station_code to indicate which station to import. We first load SWMPr and then use the function to import data for the Apalachicola Dry Bar station:\n\n# load SWMPr\nlibrary(SWMPr)\n\n# import data\napadbwq &lt;- import_local(path = 'data/367272.zip', station_code = 'apadbwq')\n\n# characteristics of the dataset\nhead(apadbwq)\n\n        datetimestamp temp f_temp spcond f_spcond  sal f_sal do_pct f_do_pct\n1 2017-01-01 00:00:00 15.9    &lt;0&gt;  34.99      &lt;0&gt; 22.1   &lt;0&gt;  104.1      &lt;0&gt;\n2 2017-01-01 00:15:00 15.9    &lt;0&gt;  34.94      &lt;0&gt; 22.0   &lt;0&gt;  104.0      &lt;0&gt;\n3 2017-01-01 00:30:00 15.9    &lt;0&gt;  34.90      &lt;0&gt; 22.0   &lt;0&gt;  103.5      &lt;0&gt;\n4 2017-01-01 00:45:00 15.9    &lt;0&gt;  34.94      &lt;0&gt; 22.0   &lt;0&gt;  103.3      &lt;0&gt;\n5 2017-01-01 01:00:00 15.9    &lt;0&gt;  34.99      &lt;0&gt; 22.1   &lt;0&gt;  104.1      &lt;0&gt;\n6 2017-01-01 01:15:00 15.9    &lt;0&gt;  35.08      &lt;0&gt; 22.1   &lt;0&gt;  103.9      &lt;0&gt;\n  do_mgl f_do_mgl depth f_depth cdepth f_cdepth level f_level clevel f_clevel\n1    9.0      &lt;0&gt;  1.88     &lt;0&gt;   1.81      &lt;3&gt;    NA    &lt;-1&gt;     NA     &lt;NA&gt;\n2    9.0      &lt;0&gt;  1.88     &lt;0&gt;   1.81      &lt;3&gt;    NA    &lt;-1&gt;     NA     &lt;NA&gt;\n3    9.0      &lt;0&gt;  1.89     &lt;0&gt;   1.82      &lt;3&gt;    NA    &lt;-1&gt;     NA     &lt;NA&gt;\n4    8.9      &lt;0&gt;  1.89     &lt;0&gt;   1.83      &lt;3&gt;    NA    &lt;-1&gt;     NA     &lt;NA&gt;\n5    9.0      &lt;0&gt;  1.90     &lt;0&gt;   1.84      &lt;3&gt;    NA    &lt;-1&gt;     NA     &lt;NA&gt;\n6    9.0      &lt;0&gt;  1.90     &lt;0&gt;   1.84      &lt;3&gt;    NA    &lt;-1&gt;     NA     &lt;NA&gt;\n   ph f_ph turb f_turb chlfluor f_chlfluor\n1 8.3  &lt;0&gt;   15    &lt;0&gt;       NA       &lt;-1&gt;\n2 8.2  &lt;0&gt;   15    &lt;0&gt;       NA       &lt;-1&gt;\n3 8.3  &lt;0&gt;   13    &lt;0&gt;       NA       &lt;-1&gt;\n4 8.3  &lt;0&gt;   16    &lt;0&gt;       NA       &lt;-1&gt;\n5 8.3  &lt;0&gt;   10    &lt;0&gt;       NA       &lt;-1&gt;\n6 8.3  &lt;0&gt;   14    &lt;0&gt;       NA       &lt;-1&gt;\n\ndim(apadbwq)\n\n[1] 105120     25\n\nrange(apadbwq$datetimestamp)\n\n[1] \"2017-01-01 00:00:00 EST\" \"2019-12-31 23:45:00 EST\"\n\n\nNote that this function was able to import and combine data from multiple csv files. We would have had to do this by hand if we were importing data with more general import functions available in R (e.g., read.csv).",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "02_dataprep.html#cleaning-and-combining-swmp-data",
    "href": "02_dataprep.html#cleaning-and-combining-swmp-data",
    "title": "2  Data Preparation",
    "section": "2.5 Cleaning and combining SWMP data",
    "text": "2.5 Cleaning and combining SWMP data\nEach row has data for multiple parameters at 15 minute intervals. Each parameter also includes a column with QAQC flags, i.e., f_ then the parameter name. We can use the qaqc function to “screen” observations with specific QAQC flags. We’ll keep all observations that have the flags 0, 1, 2, 3, 4, and 5 by indicating this information in the qaqc_keep argument (in practice, you may only want to keep data with a “zero” flag). You can view a tabular summary of the flags in a dataset using the qaqcchk function.\n\n# keep only observations that passed qaqc chekcs\napadbwq &lt;- qaqc(apadbwq, qaqc_keep = c('0', '1', '2', '3', '4', '5'))\n\n# check the results\nhead(apadbwq)\n\n        datetimestamp temp spcond  sal do_pct do_mgl depth cdepth level clevel\n1 2017-01-01 00:00:00 15.9  34.99 22.1  104.1    9.0  1.88   1.81    NA     NA\n2 2017-01-01 00:15:00 15.9  34.94 22.0  104.0    9.0  1.88   1.81    NA     NA\n3 2017-01-01 00:30:00 15.9  34.90 22.0  103.5    9.0  1.89   1.82    NA     NA\n4 2017-01-01 00:45:00 15.9  34.94 22.0  103.3    8.9  1.89   1.83    NA     NA\n5 2017-01-01 01:00:00 15.9  34.99 22.1  104.1    9.0  1.90   1.84    NA     NA\n6 2017-01-01 01:15:00 15.9  35.08 22.1  103.9    9.0  1.90   1.84    NA     NA\n   ph turb chlfluor\n1 8.3   15       NA\n2 8.2   15       NA\n3 8.3   13       NA\n4 8.3   16       NA\n5 8.3   10       NA\n6 8.3   14       NA\n\ndim(apadbwq)\n\n[1] 105120     13\n\nrange(apadbwq$datetimestamp)\n\n[1] \"2017-01-01 00:00:00 EST\" \"2019-12-31 23:45:00 EST\"\n\n\nNotice that the number of rows are the same as before - no rows are removed by qaqc. Values that did not fit the screening criteria are given a NA value. Also notice the flag columns are removed.\nThe EBASE functions also require weather data. We can repeat the steps above to import and clean data from the weather station at Apalachicola.\n\n# import weather data, clean it up\napaebmet &lt;- import_local(path = 'data/367272.zip', station_code = 'apaebmet')\napaebmet &lt;- qaqc(apaebmet, qaqc_keep = c('0', '1', '2', '3', '4', '5'))\n\n# check the results\nhead(apaebmet)\n\n        datetimestamp atemp rh   bp wspd maxwspd wdir sdwdir totpar totprcp\n1 2017-01-01 00:00:00  15.7 89 1020  4.8     6.7   97     10      0       0\n2 2017-01-01 00:15:00  15.8 90 1020  4.9     6.5  103      9      0       0\n3 2017-01-01 00:30:00  16.1 91 1020  3.8     5.8  107     11      0       0\n4 2017-01-01 00:45:00  16.5 92 1019  3.3     6.4  119     15      0       0\n5 2017-01-01 01:00:00  16.9 93 1019  5.3     8.6  113      9      0       0\n6 2017-01-01 01:15:00  17.3 93 1019  3.9     5.6  118     10      0       0\n  totsorad\n1       NA\n2       NA\n3       NA\n4       NA\n5       NA\n6       NA\n\ndim(apaebmet)\n\n[1] 105120     11\n\nrange(apaebmet$datetimestamp)\n\n[1] \"2017-01-01 00:00:00 EST\" \"2019-12-31 23:45:00 EST\"\n\n\nThe comb function in SWMPr lets us combine data from two locations using the datetimestamp column. We need to do this to use the functions in EBASE that require both water quality and weather data.\nThere are a couple of arguments to consider for the comb function. First, the timestep argument defines the time step for the resulting output. Keep this at 15 to retain all of the data. You could use a larger time step to subset the data if, for example, we wanted data every 60 minutes. Second, the method argument defines how two datasets with different date ranges are combined. Use method = 'union' to retain the entire date range across both datasets or use method = 'intersect' to retain only the dates that include data from both datasets. For our example, union and intersect produce the same results since the date ranges and time steps are the same.\nTo speed up the examples in our lesson, we’ll use a 60 minute timestep. In practice, it’s better to retain all of the data (i.e., timestep = 15).\n\n# combine water quality and weather data\napadb &lt;- comb(apadbwq, apaebmet, timestep = 60, method = 'union')\n\n# check the results\nhead(apadb)\n\n        datetimestamp temp spcond  sal do_pct do_mgl depth cdepth level clevel\n1 2017-01-01 00:00:00 15.9  34.99 22.1  104.1    9.0  1.88   1.81    NA     NA\n2 2017-01-01 01:00:00 15.9  34.99 22.1  104.1    9.0  1.90   1.84    NA     NA\n3 2017-01-01 02:00:00 15.9  35.22 22.2  103.5    9.0  1.94   1.89    NA     NA\n4 2017-01-01 03:00:00 16.0  36.95 23.4  100.1    8.6  2.00   1.95    NA     NA\n5 2017-01-01 04:00:00 16.0  37.10 23.5   99.7    8.5  2.01   1.96    NA     NA\n6 2017-01-01 05:00:00 16.1  37.19 23.6   98.8    8.4  2.01   1.96    NA     NA\n   ph turb chlfluor atemp rh   bp wspd maxwspd wdir sdwdir totpar totprcp\n1 8.3   15       NA  15.7 89 1020  4.8     6.7   97     10      0       0\n2 8.3   10       NA  16.9 93 1019  5.3     8.6  113      9      0       0\n3 8.3   13       NA  18.3 94 1018  3.9     5.2  121      7      0       0\n4 8.2   22       NA  19.0 92 1018  4.6     6.3  151      8      0       0\n5 8.2   28       NA  19.5 90 1018  5.0     6.8  153      9      0       0\n6 8.2   11       NA  19.4 90 1018  4.2     6.3  151      9      0       0\n  totsorad\n1       NA\n2       NA\n3       NA\n4       NA\n5       NA\n6       NA\n\ndim(apadb)\n\n[1] 26281    23\n\nrange(apadb$datetimestamp)\n\n[1] \"2017-01-01 EST\" \"2020-01-01 EST\"\n\n\n\n\n\n\n\n\n Exercise 1\n\n\n\nRepeat the above examples but do this using data for the East Bay station at Apalachicola. Import data for apaebwq and abaebmet, clean them up with qaqc, and combine them with comb.\n\nCreate and name a section header in your script with Ctrl + Shift + R. Enter all exercise code in this section.\nLoad the SWMPr package with the library function. This should already be installed from last time (i.e., install.packages('SWMPr')).\nImport and clean up apaebwq with import_local and qaqc.\nImport and clean up apaebmet with import_local and qaqc.\nCombine the two with comb. Use a 60 minute time step and use the union option.\n\n\n\n\n\n\n\n Answers\n\n\n\n\n\n\n# import water quality data, clean it up\napaebwq &lt;- import_local(path = 'data/367272.zip', station_code = 'apaebwq')\napaebwq &lt;- qaqc(apaebwq, qaqc_keep = c('0', '1', '2', '3', '4', '5'))\n\n# import weather data, clean it up\napaebmet &lt;- import_local(path = 'data/367272.zip', station_code = 'apaebmet')\napaebmet &lt;- qaqc(apaebmet, qaqc_keep = c('0', '1', '2', '3', '4', '5'))\n\n# combine water quality and weather data\napaeb &lt;- comb(apaebwq, apaebmet, timestep = 60, method = 'union')",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "02_dataprep.html#preparing-swmp-data-for-ebase",
    "href": "02_dataprep.html#preparing-swmp-data-for-ebase",
    "title": "2  Data Preparation",
    "section": "2.6 Preparing SWMP data for EBASE",
    "text": "2.6 Preparing SWMP data for EBASE\nNow we want to setup our data for use with functions in the EBASE package. As with most R functions, the input formats are very specific requiring us to make sure the column names, locations, and types of columns in our data are exactly as needed.\nThe example dataset from EBASE can be used to guide us in preparing the data. We can compare this to our Apalachicola dataset from above.\n\n# view first six rows of example data\nhead(exdat)\n\n        DateTimeStamp DO_obs Temp  Sal PAR WSpd\n1 2012-02-23 00:00:00    8.8 16.4 23.0   0  3.6\n2 2012-02-23 00:15:00    8.8 16.4 22.8   0  3.5\n3 2012-02-23 00:30:00    8.8 16.4 22.7   0  3.6\n4 2012-02-23 00:45:00    8.8 16.4 22.9   0  4.2\n5 2012-02-23 01:00:00    8.7 16.4 22.7   0  3.6\n6 2012-02-23 01:15:00    8.5 16.4 23.4   0  4.1\n\n# view the structure of example data\nstr(exdat)\n\n'data.frame':   27648 obs. of  6 variables:\n $ DateTimeStamp: POSIXct, format: \"2012-02-23 00:00:00\" \"2012-02-23 00:15:00\" ...\n $ DO_obs       : num  8.8 8.8 8.8 8.8 8.7 8.5 8.3 8.2 7.8 8.5 ...\n $ Temp         : num  16.4 16.4 16.4 16.4 16.4 16.4 16.4 16.4 16.4 16.4 ...\n $ Sal          : num  23 22.8 22.7 22.9 22.7 23.4 24.5 24.4 24.3 23 ...\n $ PAR          : num  0 0 0 0 0 0 0 0 0 0 ...\n $ WSpd         : num  3.6 3.5 3.6 4.2 3.6 4.1 3.6 4.2 4 3.6 ...\n\n# view first six rows of apadb data\nhead(apadb)\n\n        datetimestamp temp spcond  sal do_pct do_mgl depth cdepth level clevel\n1 2017-01-01 00:00:00 15.9  34.99 22.1  104.1    9.0  1.88   1.81    NA     NA\n2 2017-01-01 01:00:00 15.9  34.99 22.1  104.1    9.0  1.90   1.84    NA     NA\n3 2017-01-01 02:00:00 15.9  35.22 22.2  103.5    9.0  1.94   1.89    NA     NA\n4 2017-01-01 03:00:00 16.0  36.95 23.4  100.1    8.6  2.00   1.95    NA     NA\n5 2017-01-01 04:00:00 16.0  37.10 23.5   99.7    8.5  2.01   1.96    NA     NA\n6 2017-01-01 05:00:00 16.1  37.19 23.6   98.8    8.4  2.01   1.96    NA     NA\n   ph turb chlfluor atemp rh   bp wspd maxwspd wdir sdwdir totpar totprcp\n1 8.3   15       NA  15.7 89 1020  4.8     6.7   97     10      0       0\n2 8.3   10       NA  16.9 93 1019  5.3     8.6  113      9      0       0\n3 8.3   13       NA  18.3 94 1018  3.9     5.2  121      7      0       0\n4 8.2   22       NA  19.0 92 1018  4.6     6.3  151      8      0       0\n5 8.2   28       NA  19.5 90 1018  5.0     6.8  153      9      0       0\n6 8.2   11       NA  19.4 90 1018  4.2     6.3  151      9      0       0\n  totsorad\n1       NA\n2       NA\n3       NA\n4       NA\n5       NA\n6       NA\n\n# view the structure of apadb data\nstr(apadb)\n\nClasses 'swmpr' and 'data.frame':   26281 obs. of  23 variables:\n $ datetimestamp: POSIXct, format: \"2017-01-01 00:00:00\" \"2017-01-01 01:00:00\" ...\n $ temp         : num  15.9 15.9 15.9 16 16 16.1 16.2 16.2 16.1 16.3 ...\n $ spcond       : num  35 35 35.2 37 37.1 ...\n $ sal          : num  22.1 22.1 22.2 23.4 23.5 23.6 23.7 23.2 22.4 23.3 ...\n $ do_pct       : num  104.1 104.1 103.5 100.1 99.7 ...\n $ do_mgl       : num  9 9 9 8.6 8.5 8.4 8.1 8.1 8.2 7.9 ...\n $ depth        : num  1.88 1.9 1.94 2 2.01 2.01 1.95 1.89 1.81 1.74 ...\n $ cdepth       : num  1.81 1.84 1.89 1.95 1.96 1.96 1.9 1.84 1.75 1.68 ...\n $ level        : num  NA NA NA NA NA NA NA NA NA NA ...\n $ clevel       : num  NA NA NA NA NA NA NA NA NA NA ...\n $ ph           : num  8.3 8.3 8.3 8.2 8.2 8.2 8.1 8.1 8.1 8.1 ...\n $ turb         : num  15 10 13 22 28 11 23 26 26 27 ...\n $ chlfluor     : num  NA NA NA NA NA NA NA NA NA NA ...\n $ atemp        : num  15.7 16.9 18.3 19 19.5 19.4 19.3 19.7 19.7 20.3 ...\n $ rh           : num  89 93 94 92 90 90 91 89 90 90 ...\n $ bp           : num  1020 1019 1018 1018 1018 ...\n $ wspd         : num  4.8 5.3 3.9 4.6 5 4.2 4.3 5.3 4.9 5.6 ...\n $ maxwspd      : num  6.7 8.6 5.2 6.3 6.8 6.3 5.6 7.5 7.2 7.5 ...\n $ wdir         : num  97 113 121 151 153 151 147 153 155 156 ...\n $ sdwdir       : num  10 9 7 8 9 9 8 9 10 9 ...\n $ totpar       : num  0 0 0 0 0 ...\n $ totprcp      : num  0 0 0 0 0 0 0 0 0 0 ...\n $ totsorad     : num  NA NA NA NA NA NA NA NA NA NA ...\n - attr(*, \"station\")= chr [1:2] \"apadbwq\" \"apaebmet\"\n - attr(*, \"parameters\")= chr [1:22] \"temp\" \"spcond\" \"sal\" \"do_pct\" ...\n - attr(*, \"qaqc_cols\")= logi FALSE\n - attr(*, \"cens_cols\")= logi FALSE\n - attr(*, \"date_rng\")= POSIXct[1:2], format: \"2017-01-01\" \"2020-01-01\"\n - attr(*, \"timezone\")= chr \"America/Jamaica\"\n - attr(*, \"stamp_class\")= chr [1:2] \"POSIXct\" \"POSIXt\"\n\n\nSo, we need to do a few things to our Apalachicola dataset to match the format of the exdat dataset. We can use the dplyr package to “wrangle” the data into the correct format (here’s a useful cheatsheet for this package). The dplyr package comes with the tidyverse.\nAll we need to do is rename the columns and select those we want in the correct order. This can all be done with the select function in dplyr.\n\n# load dplyr\nlibrary(dplyr)\n\n# select and rename columns\napadb &lt;- select(apadb,\n  DateTimeStamp = datetimestamp,\n  DO_obs = do_mgl,\n  Temp = temp,\n  Sal = sal,\n  PAR = totpar,\n  WSpd = wspd,\n)\n\n# show first six rows\nhead(apadb)\n\n        DateTimeStamp DO_obs Temp  Sal PAR WSpd\n1 2017-01-01 00:00:00    9.0 15.9 22.1   0  4.8\n2 2017-01-01 01:00:00    9.0 15.9 22.1   0  5.3\n3 2017-01-01 02:00:00    9.0 15.9 22.2   0  3.9\n4 2017-01-01 03:00:00    8.6 16.0 23.4   0  4.6\n5 2017-01-01 04:00:00    8.5 16.0 23.5   0  5.0\n6 2017-01-01 05:00:00    8.4 16.1 23.6   0  4.2\n\n# view structure\nstr(apadb)\n\nClasses 'swmpr' and 'data.frame':   26281 obs. of  6 variables:\n $ DateTimeStamp: POSIXct, format: \"2017-01-01 00:00:00\" \"2017-01-01 01:00:00\" ...\n $ DO_obs       : num  9 9 9 8.6 8.5 8.4 8.1 8.1 8.2 7.9 ...\n $ Temp         : num  15.9 15.9 15.9 16 16 16.1 16.2 16.2 16.1 16.3 ...\n $ Sal          : num  22.1 22.1 22.2 23.4 23.5 23.6 23.7 23.2 22.4 23.3 ...\n $ PAR          : num  0 0 0 0 0 ...\n $ WSpd         : num  4.8 5.3 3.9 4.6 5 4.2 4.3 5.3 4.9 5.6 ...\n\n\nWe can also verify the column names are the same between the two datasets. Note the use of two equal signs - this is how we tell R to test for equality.\n\nnames(apadb) == names(exdat)\n\n[1] TRUE TRUE TRUE TRUE TRUE TRUE\n\n\nThe last thing we need to do is to make sure the units are correct. Looking at the requirements in Section 2.3 and those from the CDMO website, all of the data are in the correct units except for PAR. This should be in Watts per square meter, whereas the data are millimoles per square meter per 15 minute logging interval. Morel and Smith (1974) provide the following conversion factor:\n\\[\n1 \\, \\mu mol \\, m^{-2} \\, s^{-1} = 0.2175 \\, W \\, m^{-2}\n\\] Before we apply the conversion factor, we need to convert the units of PAR from millimoles to micromoles and from per 15 minutes to per second. This can be done by simply multiply PAR by 1000 (milli to micro) and dividing by 900 (15 minutes = 900 seconds). The final conversion will look like this:\n\\[\n1 \\, W \\, m^{-2} = 1 \\, mmol \\, m^{-2} \\, 15min^{-1} * 1000 / 900 * 0.2175\n\\]\nWe can use the mutate function in dplyr to convert this.\n\n# convert PAR to Watts per square meter\napadb &lt;- apadb |&gt; \n  mutate(\n    PAR = PAR * 1000 / 900 * 0.2175\n  )\n\nThe Apalachicola data should now work with EBASE. However, a few additional exploratory analyses are worthwhile before we use these data. Most functions in R deal with missing data by either not working at all or providing some work-around to accommodate the missing values. The functions in EBASE are in the latter category and we’ll discuss how this is done in Lesson 3. However, knowing how much and where missing observations occur is still important for interpreting results.\nMissing data in SWMP are not uncommon and they often occur when sondes or other equipment are down for maintenance or are otherwise broken for a period of time. Missing observations usually come in blocks where all parameters are unavailable, as opposed to only one parameter. Below, we can quickly see how many missing observations occur in column.\n\napply(apadb, 2, function(x) sum(is.na(x)))\n\nDateTimeStamp        DO_obs          Temp           Sal           PAR \n            0          6307          6307          6307          7816 \n         WSpd \n         7419 \n\n\nThere are quite a few missing observations. Let’s create some quick plots to see where these occur. We’ll use the plotly R package that lets us dynamically interact with the data (Sievert 2020).\n\nlibrary(plotly)\n\nplot_ly(apadb, x = ~DateTimeStamp, y = ~DO_obs, type = 'scatter', mode = 'lines')\n\n\n\n\n\nThere’s a huge gap in the fall of 2018 and the latter half of 2019. Using these years to estimate metabolism may not be advisable.\nSimilarly, the weather data also have missing observations. What may have caused this gap?\n\nplot_ly(apadb, x = ~DateTimeStamp, y = ~WSpd, type = 'scatter', mode = 'lines')\n\n\n\n\n\nThis brief assessment can give us information on which years of data are useful to interpret for metabolism. A more detailed analysis of the quality of the data is needed before more formal analyses, including an assessment of the QC codes in the SWMP data. This quick assessment will suffice for now.\n\n\n\n\n\n\n: Exercise 2\n\n\n\nRepeat the above examples but use the combined dataset for the Apalachicola Bay East Bay data that you created in Exercise 1.\n\nCreate a new section in your script using Ctrl + Shift + R and give it an appropriate name.\nLoad the dplyr package with the library function.\nSimultaneously rename and select the columns for date/time (DateTimeStamp = datetimestamp), dissolved oxygen (DO_obs = do_mgl), water temperature (Temp = temp), salinity (Sal = sal), PAR (PAR = par), and wind speed (WSpd = wspd) with the select function from dplyr. Don’t forget to assign the new dataset to an object in your workspace (with &lt;-).\nConvert PAR to the correct units.\n\n\n\n\n\n\n\n Answers\n\n\n\n\n\n\n# select and rename columns\napaeb &lt;- select(apaeb,\n  DateTimeStamp = datetimestamp,\n  DO_obs = do_mgl,\n  Temp = temp,\n  Sal = sal,\n  PAR = totpar,\n  WSpd = wspd,\n)\n\n# convert PAR\napaeb &lt;- apaeb |&gt; \n  mutate(\n    PAR = PAR * 1000 / 900 * 0.2175\n  )",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "02_dataprep.html#preparing-other-data",
    "href": "02_dataprep.html#preparing-other-data",
    "title": "2  Data Preparation",
    "section": "2.7 Preparing other data",
    "text": "2.7 Preparing other data\nLong-term continuous monitoring data from other sources can be used with EBASE. As above, the data must include relevant water quality and weather data at an appropriate time step. This section will show you how to prepare generic data with more general tools in R.\nData from Tampa Bay will be used in this example. We’ll pull water quality data from a continuous monitoring platform in the lower bay and weather data from a nearby NOAA monitoring station. The data are available here and can be downloaded through their API. Take a look at the URL to see how the API is queried.\n\nurl &lt;- 'http://tampabay.loboviz.com/cgi-data/nph-data.cgi?node=82&min_date=20210701&max_date=20210801&y=salinity,temperature,oxygen,par&data_format=text'\n\nlobo &lt;- read.table(url, skip = 2, sep = '\\t', header = T)\nhead(lobo)\n\n           date..EST. salinity..PSU. temperature..C. dissolved.oxygen..mg.L.\n1 2021-07-01 00:30:00          23.95           28.59                    4.73\n2 2021-07-01 01:30:00          24.03           28.58                    4.56\n3 2021-07-01 02:30:00          25.26           28.84                    4.60\n4 2021-07-01 03:30:00          25.77           28.79                    4.41\n5 2021-07-01 04:30:00          26.12           28.86                    4.31\n6 2021-07-01 05:30:00          26.35           28.89                    4.36\n  PAR..uM.m.2.sec.\n1            0.044\n2            0.044\n3            0.044\n4            0.044\n5            0.044\n6            0.244\n\nstr(lobo)\n\n'data.frame':   768 obs. of  5 variables:\n $ date..EST.             : chr  \"2021-07-01 00:30:00\" \"2021-07-01 01:30:00\" \"2021-07-01 02:30:00\" \"2021-07-01 03:30:00\" ...\n $ salinity..PSU.         : num  23.9 24 25.3 25.8 26.1 ...\n $ temperature..C.        : num  28.6 28.6 28.8 28.8 28.9 ...\n $ dissolved.oxygen..mg.L.: num  4.73 4.56 4.6 4.41 4.31 4.36 4.48 4.45 4.49 4.76 ...\n $ PAR..uM.m.2.sec.       : num  0.044 0.044 0.044 0.044 0.044 ...\n\n\nThe data are not in the right format for EBASE. We need to change the names, convert the date/time column to a POSIXct object with the correct time zone, and convert the PAR data to the correct units. PAR is micromoles per square meter per second, so we need to convert this to Watts per square meter. First, we select and rename the columns.\n\nlobo &lt;- lobo |&gt; \n  select(\n    DateTimeStamp = date..EST.,\n    DO_obs = dissolved.oxygen..mg.L.,\n    Temp = temperature..C.,\n    Sal = salinity..PSU.,\n    PAR = PAR..uM.m.2.sec.\n  )\n\nNext, we use mutate to convert the date/time column to a POSIXct object and the PAR data to the correct units. For date/time, we can use a function from the lubridate package and use the “America/Jamaica” time zone, which is eastern time without daylight savings. Note that this step is not needed for SWMP data since the SWMPr package automatically converts the date/time column using the correct time zone. The PAR column is converted using the same formula from above, except we don’t need to convert from millimoles to micromoles and from 15 minutes to seconds.\n\nlobo &lt;- lobo |&gt; \n  mutate(\n    DateTimeStamp = lubridate::ymd_hms(DateTimeStamp, tz = 'America/Jamaica'),\n    PAR = PAR * 0.2175\n  )\n\nNext we import the weather data. These can be similarly downloaded using the NOAA Tides & Currents API. Again, note how the URL is specified to get the data we want.\n\nurl &lt;- 'https://api.tidesandcurrents.noaa.gov/api/prod/datagetter?product=wind&application=NOS.COOPS.TAC.MET&begin_date=20210701&end_date=20210801&station=8726520&time_zone=LST&units=metric&format=CSV'\n\nports &lt;- read.table(url, sep = ',', header = T)\nhead(ports)\n\n         Date.Time Speed Direction Direction.1 Gust X R\n1 2021-07-01 00:00   1.2        88           E  2.0 0 0\n2 2021-07-01 00:06   1.6       101           E  2.2 0 0\n3 2021-07-01 00:12   0.8       101           E  2.3 0 0\n4 2021-07-01 00:18   1.5        83           E  2.3 0 0\n5 2021-07-01 00:24   1.4        89           E  2.2 0 0\n6 2021-07-01 00:30   1.3        94           E  2.5 0 0\n\nstr(ports)\n\n'data.frame':   7680 obs. of  7 variables:\n $ Date.Time  : chr  \"2021-07-01 00:00\" \"2021-07-01 00:06\" \"2021-07-01 00:12\" \"2021-07-01 00:18\" ...\n $ Speed      : num  1.2 1.6 0.8 1.5 1.4 1.3 1.2 1.2 1.8 2.4 ...\n $ Direction  : num  88 101 101 83 89 94 83 86 87 90 ...\n $ Direction.1: chr  \"E\" \"E\" \"E\" \"E\" ...\n $ Gust       : num  2 2.2 2.3 2.3 2.2 2.5 2.5 2.9 2.8 3.3 ...\n $ X          : int  0 0 0 0 0 0 0 0 0 0 ...\n $ R          : int  0 0 0 0 0 0 0 0 0 0 ...\n\n\nSimilar to the water quality data, we need to select and rename the columns and convert the date/time column to a POSIXct object with the correct time zone. Instead of ymd_hms() as above, we’ll use ymd_hm() because seconds are not included. We’ll do this in one step.\n\nports &lt;- ports |&gt; \n  select(\n    DateTimeStamp = Date.Time,\n    WSpd = Speed\n  ) |&gt; \n  mutate(\n    DateTimeStamp = lubridate::ymd_hm(DateTimeStamp, tz = 'America/Jamaica')\n  )\n\nThe last step is to combine the water quality and weather data. We can use a simple join function from the dplyr package. The water quality and weather data are at different time steps, where the water quality data is every hour on the 30 minute mark and the weather data are every six minutes. Because the weather data also include observations on the 30 minute mark, we can just left join them to the water quality data, retaining only those data on the 30 minute mark. See here for more information about joins.\n\ntbdat &lt;- left_join(lobo, ports, by = 'DateTimeStamp')\n\nhead(tbdat)\n\n        DateTimeStamp DO_obs  Temp   Sal     PAR WSpd\n1 2021-07-01 00:30:00   4.73 28.59 23.95 0.00957  1.3\n2 2021-07-01 01:30:00   4.56 28.58 24.03 0.00957  2.2\n3 2021-07-01 02:30:00   4.60 28.84 25.26 0.00957  1.3\n4 2021-07-01 03:30:00   4.41 28.79 25.77 0.00957  2.0\n5 2021-07-01 04:30:00   4.31 28.86 26.12 0.00957  2.2\n6 2021-07-01 05:30:00   4.36 28.89 26.35 0.05307  3.0\n\nstr(tbdat)\n\n'data.frame':   768 obs. of  6 variables:\n $ DateTimeStamp: POSIXct, format: \"2021-07-01 00:30:00\" \"2021-07-01 01:30:00\" ...\n $ DO_obs       : num  4.73 4.56 4.6 4.41 4.31 4.36 4.48 4.45 4.49 4.76 ...\n $ Temp         : num  28.6 28.6 28.8 28.8 28.9 ...\n $ Sal          : num  23.9 24 25.3 25.8 26.1 ...\n $ PAR          : num  0.00957 0.00957 0.00957 0.00957 0.00957 ...\n $ WSpd         : num  1.3 2.2 1.3 2 2.2 3 2.9 1.7 2 1.3 ...\n\n\nWe see that the final dataset has the same number of rows as the water quality data and a wind speed column has been added from the weather data. Now the data are ready for analysis.\n\n\n\n\n\n\n: Exercise 2\n\n\n\nWe’ll want to visually evaluate the Tampa Bay data before using EBASE.\n\nCreate and name a section header in your script with Ctrl + Shift + R. Enter all exercise code in this section.\nLoad the plotly package with the library function.\nUse the plotly package to create some time series plots for variables of interest.\n\nLook for gaps or outliers.\nLook for interesting trends that might influence how you interpret metabolism.\n\n\n\n\n\n\n\n Answers\n\n\n\n\n\n\nlibrary(plotly)\n\nplot_ly(tbdat, x = ~DateTimeStamp, y = ~DO_obs, type = 'scatter', mode = 'lines')\nplot_ly(tbdat, x = ~DateTimeStamp, y = ~Temp, type = 'scatter', mode = 'lines')\nplot_ly(tbdat, x = ~DateTimeStamp, y = ~Sal, type = 'scatter', mode = 'lines')\nplot_ly(tbdat, x = ~DateTimeStamp, y = ~PAR, type = 'scatter', mode = 'lines')\nplot_ly(tbdat, x = ~DateTimeStamp, y = ~WSpd, type = 'scatter', mode = 'lines')",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "02_dataprep.html#next-steps",
    "href": "02_dataprep.html#next-steps",
    "title": "2  Data Preparation",
    "section": "2.8 Next steps",
    "text": "2.8 Next steps\nThe most difficult part of using EBASE is preparing the data. Now that we have learned how to import and clean the data, we are ready for analysis. In the next lesson, we’ll learn about the theory behind EBASE, how to use it to estimate metabolism, and how to interpret the results.\n\n\n\n\nBeck, M. W. 2016. SWMPr: An R package for retrieving, organizing, and analyzing environmental data for estuaries. R Journal 8: 219–232.\n\n\nMorel, A., and R. C. Smith. 1974. Relation between total quanta and total energy for aquatic photosynthesis. Limnology and Oceanography 19: 591–600. doi:10.4319/lo.1974.19.4.0591\n\n\nSievert, C. 2020. Interactive web-based data visualization with r, plotly, and shiny, Chapman; Hall/CRC.",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "03_ebase.html",
    "href": "03_ebase.html",
    "title": "3  Using EBASE",
    "section": "",
    "text": "3.1 Lesson Outline\nThis lesson will explain the basic theory behind ecosystem metabolism and how EBASE is used to estimate key parameters. EBASE is a Bayesian implementation for estimating metabolism that differs from more conventional approaches. We’ll also explore the main functions of EBASE to estimate metabolism, how the Bayesian approach can be used to incorporate prior knowledge, and interpret the results.",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Using EBASE</span>"
    ]
  },
  {
    "objectID": "03_ebase.html#learning-goals",
    "href": "03_ebase.html#learning-goals",
    "title": "3  Using EBASE",
    "section": "3.2 Learning Goals",
    "text": "3.2 Learning Goals\n\nUnderstand the basic theory behind ecosystem metabolism\nLearn how EBASE is used to estimate key parameters\nUnderstand the Bayesian approach to estimating metabolism\nUse the main functions of EBASE to estimate metabolism\nInterpret the results of EBASE",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Using EBASE</span>"
    ]
  },
  {
    "objectID": "03_ebase.html#next-steps",
    "href": "03_ebase.html#next-steps",
    "title": "3  Using EBASE",
    "section": "3.3 Next steps",
    "text": "3.3 Next steps\nYou now understand the basics of ecosystem metabolism and how EBASE is used to estimate key parameters using a Bayesian approach. We’ve explored additional functions in EBASE to help interpret the results, which include an evaluation of goodness of fit and various plotting methods. Next, we’ll explore the EBASE results in more detail to demonstrate how the results can inform the understanding of ecosystem health and function.",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Using EBASE</span>"
    ]
  },
  {
    "objectID": "04_interpret.html",
    "href": "04_interpret.html",
    "title": "4  Interpreting Results",
    "section": "",
    "text": "4.1 Discussion Outline\nThis discussion is your time to share some ideas about evaluating the results from EBASE. We’ll go through some live coding examples based on these ideas. Below are some examples and code to get us started.",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Interpreting Results</span>"
    ]
  },
  {
    "objectID": "04_interpret.html#example-1-compare-results-to-nutrient-data",
    "href": "04_interpret.html#example-1-compare-results-to-nutrient-data",
    "title": "4  Interpreting Results",
    "section": "4.2 Example 1: Compare results to nutrient data",
    "text": "4.2 Example 1: Compare results to nutrient data",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Interpreting Results</span>"
    ]
  },
  {
    "objectID": "04_interpret.html#example-2-site-comparisons",
    "href": "04_interpret.html#example-2-site-comparisons",
    "title": "4  Interpreting Results",
    "section": "4.3 Example 2: Site comparisons",
    "text": "4.3 Example 2: Site comparisons",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Interpreting Results</span>"
    ]
  },
  {
    "objectID": "04_interpret.html#next-steps",
    "href": "04_interpret.html#next-steps",
    "title": "4  Interpreting Results",
    "section": "4.4 Next steps",
    "text": "4.4 Next steps\nThis concludes our workshop on using EBASE to estimate ecosystem metabolism. You should now have a baseline understanding of how these tools can be used to gain insights into ecosystem properties and the factors that may be influencing them. Please follow up with the instructor if you have additional questions or would like to explore more advanced topics.",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Interpreting Results</span>"
    ]
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Appendix A — Setup for the workshop",
    "section": "",
    "text": "A.1 Install R and RStudio\nR and RStudio are separate downloads and installations. R is the underlying statistical computing software. RStudio is a graphical integrated development environment (IDE) that makes using R much easier and more interactive. You need to install R before you install RStudio.\nThanks to the USGS-R Training group and Data Carpentry for making their installation materials available. The following instructions come directly from their materials, with a few minor edits to help you get set up.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Setup for the workshop</span>"
    ]
  },
  {
    "objectID": "setup.html#install-r-and-rstudio",
    "href": "setup.html#install-r-and-rstudio",
    "title": "Appendix A — Setup for the workshop",
    "section": "",
    "text": "A.1.1 Windows: Download and install R\nGo to CRAN and download the R installer for Windows. Make sure to choose the latest stable version (v4.4.1 as of August 2024).\nOnce the installer downloads, Right-click on it and select “Run as administrator”.\nType in your credentials and click yes (or if you don’t have administrator access have your IT rep install with Admin privileges).\n\nYou can click next through the standard dialogs and accept most defaults. But at the destination screen, please verify that it is installing it to C:\\Program Files\\R\n\nAt the “Select Components” screen, you can accept the default and install both 32-bit and 64-bit versions.\n\nAt this screen, uncheck ‘Create a desktop icon’ because non-admin users in Windows will be unable to delete it.\n\n\n\nA.1.2 Windows: Download and install RStudio\nDownload RStudio from here.\nAfter download, double-click the installer. It will ask for your administrator credentials to install (you might need to have your IT rep install again).\nAccept all the default options for the RStudio install.\n\n\n\nA.1.3 macOS: Download and install R\n\nDownload and install R from the CRAN website for Mac here.\nSelect the .pkg file for the latest R version\nDouble click on the downloaded file to install R\nIt is also a good idea to install XQuartz (needed by some packages)\n\n\n\nA.1.4 macOS: Download and install RStudio\n\nGo to the RStudio download page\nUnder Installers select the appropriate RStudio download file for macOS\nDouble click the file to install RStudio\n\n\n\nA.1.5 Check Install\nOnce installed, RStudio should be accessible from the start menu. Start up RStudio. Once running it should look something like this:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Setup for the workshop</span>"
    ]
  },
  {
    "objectID": "setup.html#sec-instjags",
    "href": "setup.html#sec-instjags",
    "title": "Appendix A — Setup for the workshop",
    "section": "A.2 Install JAGS",
    "text": "A.2 Install JAGS\nThe JAGS software is a separate open-source program for analyzing Bayesian hierarchical models using Markov Chain Monte Carlo (MCMC) methods. It is used by EBASE to run the Bayesian models. Follow the instructions here to download and install the version appropriate for your operating system.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Setup for the workshop</span>"
    ]
  },
  {
    "objectID": "setup.html#sec-instpackages",
    "href": "setup.html#sec-instpackages",
    "title": "Appendix A — Setup for the workshop",
    "section": "A.3 Install R packages",
    "text": "A.3 Install R packages\nWe’ll use the following R packages during the workshop. Install them in the RStudio console by running these commands:\ninstall.packages('EBASE')\ninstall.packages('SWMPr')\ninstall.packages('tidyverse')\ninstall.packages('plotly')\nAfter installation, check the packages can be loaded without error:\nlibrary(EBASE)\nlibrary(SWMPr)\nlibrary(tidyverse)\nlibrary(plotly)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Setup for the workshop</span>"
    ]
  },
  {
    "objectID": "setup.html#sec-data",
    "href": "setup.html#sec-data",
    "title": "Appendix A — Setup for the workshop",
    "section": "A.4 Download the data",
    "text": "A.4 Download the data\nDownload the zipped data file from here: https://github.com/fawda123/ebase-training/raw/main/data/367272.zip\nKeep the file in a known location so that we can access it during the workshop.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Setup for the workshop</span>"
    ]
  },
  {
    "objectID": "setup.html#sec-cloud",
    "href": "setup.html#sec-cloud",
    "title": "Appendix A — Setup for the workshop",
    "section": "A.5 Posit Cloud (optional)",
    "text": "A.5 Posit Cloud (optional)\nPosit Cloud provides an environment to use RStudio and the resources above through a web browser. We’ve created a workspace on Posit Cloud that includes most all of the software and packages described above. Please only use this option as a last resort. We strongly encourage installing the software on your own computer.\nOpen the following URL in a web browser: https://posit.cloud/content/8518890\nYou will see a login screen that looks like this:\n\nSign up using a personal login or existing account (Google, GitHub, etc.).\nYou’ll see the workspace in your browser once you’ve signed in. You’ll need to make a permanent copy to save your work. Just click the button at the top marked “+ Save as Permanent Copy”. When this is done, the red text at the top indicating “TEMPORARY COPY” will no longer be visible.\n\nNow you can follow along with the workshop content.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Setup for the workshop</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Beck, M. W. 2016. SWMPr: An R package for\nretrieving, organizing, and analyzing environmental data for estuaries.\nR Journal 8: 219–232.\n\n\nBeck, M. W., J. M. Arriola, M. Herrmann, and R. G. Najjar. 2024. Fitting\nmetabolic models to dissolved oxygen data: The estuarine bayesian\nsingle-station estimation method. Limnology and Oceanography: Methods\n22: 590–607. doi:10.1002/lom3.10620\n\n\nBeck, M. W., J. D. Hagy III, and M. C. Murrell. 2015. Improving\nestimates of ecosystem metabolism by reducing effects of tidal advection\non dissolved oxygen time series. Limnology and Oceanography: Methods\n13: 731–745. doi:10.1002/lom3.10062\n\n\nCaffrey, J. M. 2004. Factors controlling net ecosystem metabolism in\nU.S. estuaries. Estuaries 27: 90–101. doi:10.1007/bf02803563\n\n\nHoellein, T. J., D. A. Bruesewitz, and D. C. Richardson. 2013.\nRevisiting Odum (1956): A synthesis of aquatic ecosystem\nmetabolism. Limnology and Oceanography 58: 2089–2100.\ndoi:10.4319/lo.2013.58.6.2089\n\n\nKemp, W. M., and J. M. Testa. 2011. Metabolic\nbalance between ecosystem production and consumption, p. 83–118.\nIn E. Wolanski and D. McLusky [eds.], Treatise on estuarine and\ncoastal science. Elsevier.\n\n\nMorel, A., and R. C. Smith. 1974. Relation between total quanta and\ntotal energy for aquatic photosynthesis. Limnology and Oceanography\n19: 591–600. doi:10.4319/lo.1974.19.4.0591\n\n\nOdum, H. T. 1956. Primary production in flowing waters. Limnology and\nOceanography 1: 102–117.\n\n\nSievert, C. 2020. Interactive web-based\ndata visualization with r, plotly, and shiny, Chapman; Hall/CRC.",
    "crumbs": [
      "Appendices",
      "References"
    ]
  }
]